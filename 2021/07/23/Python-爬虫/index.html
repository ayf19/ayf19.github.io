<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"ayf19.github.io","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="0. 前言今年的Python应用相比于去年扩充了更多的内容，因此爬虫的时间也需要压缩一些，好在爬虫本身的难度并不大，只是最好知道一些背景知识，但是这些背景（除了我即将提到的）并不太影响我们今天的内容，因此大家可以看 rls的课程（的前半部分）自行了解。">
<meta property="og:type" content="article">
<meta property="og:title" content="Python 爬虫">
<meta property="og:url" content="https://ayf19.github.io/2021/07/23/Python-%E7%88%AC%E8%99%AB/">
<meta property="og:site_name" content="ayf&#39;s blog">
<meta property="og:description" content="0. 前言今年的Python应用相比于去年扩充了更多的内容，因此爬虫的时间也需要压缩一些，好在爬虫本身的难度并不大，只是最好知道一些背景知识，但是这些背景（除了我即将提到的）并不太影响我们今天的内容，因此大家可以看 rls的课程（的前半部分）自行了解。">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://ayf19.github.io/ideal.png">
<meta property="og:image" content="https://ayf19.github.io/simple.png">
<meta property="article:published_time" content="2021-07-23T10:50:31.000Z">
<meta property="article:modified_time" content="2022-07-18T08:04:16.000Z">
<meta property="article:author" content="ayf">
<meta property="article:tag" content="Python">
<meta property="article:tag" content="暑培">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://ayf19.github.io/ideal.png">

<link rel="canonical" href="https://ayf19.github.io/2021/07/23/Python-%E7%88%AC%E8%99%AB/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>Python 爬虫 | ayf's blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">ayf's blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://ayf19.github.io/2021/07/23/Python-%E7%88%AC%E8%99%AB/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="ayf">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ayf's blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Python 爬虫
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-07-23 18:50:31" itemprop="dateCreated datePublished" datetime="2021-07-23T18:50:31+08:00">2021-07-23</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2022-07-18 16:04:16" itemprop="dateModified" datetime="2022-07-18T16:04:16+08:00">2022-07-18</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%96%87%E6%A1%A3/" itemprop="url" rel="index"><span itemprop="name">文档</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>7.4k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>7 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h3 id="0-前言"><a href="#0-前言" class="headerlink" title="0. 前言"></a>0. 前言</h3><p>今年的Python应用相比于去年扩充了更多的内容，因此爬虫的时间也需要压缩一些，好在爬虫本身的难度并不大，只是最好知道一些背景知识，但是这些背景（除了我即将提到的）并不太影响我们今天的内容，因此大家可以看 <a target="_blank" rel="noopener" href="https://cloud.tsinghua.edu.cn/f/cf2c7ae3113c4369850f/">rls的课程</a>（的前半部分）自行了解。</p>
<span id="more"></span>

<h3 id="1-网络请求-amp-爬虫初步"><a href="#1-网络请求-amp-爬虫初步" class="headerlink" title="1. 网络请求 &amp; 爬虫初步"></a>1. 网络请求 &amp; 爬虫初步</h3><h4 id="1-1-终极哲学三大问（服务器视角下的网络请求）"><a href="#1-1-终极哲学三大问（服务器视角下的网络请求）" class="headerlink" title="1.1. 终极哲学三大问（服务器视角下的网络请求）"></a>1.1. 终极哲学三大问（服务器视角下的网络请求）</h4><p>爬虫为了（自动化地、常常还需要是高速地）获取服务器资源，首先应当了解向服务器发送请求时发生了什么。通常来说一次网络请求的主要内容包括：</p>
<ul>
<li>你是谁：User-Agent | Cookies</li>
<li>你从哪里来：IP</li>
<li>你来这里干什么：Method &amp; Parameter （如果是POST请求的话还会有更多内容，但是作为爬虫的话可以略微简化）</li>
</ul>
<p>在这一过程中服务器可能面临一些攻击（爬虫可能无意间导致这样的问题）：</p>
<ul>
<li>DoS (Denial of Service) attack：拒绝服务攻击，通过构造大量的（尤其是繁重的，也就是CC攻击）请求使得服务器“忙不过来”，让服务器无法正常服务；</li>
<li>DDoS (Distributed Denial of Service) attack：分布式拒绝服务攻击，在DoS攻击的基础上改为多个客户端（<del>肉鸡</del>用户）同时对目标网站发起大量请求。</li>
</ul>
<p>尽管谈论攻击有点遥远，但是不妨考虑以下两个情景：</p>
<ol>
<li>当你准时到达查询高考成绩时</li>
<li>当你双十一午夜十二点下单时</li>
</ol>
<p><strong>写爬虫时应该全力避免这种情况！</strong></p>
<h4 id="1-2-网络抓包基本功"><a href="#1-2-网络抓包基本功" class="headerlink" title="1.2. 网络抓包基本功"></a>1.2. 网络抓包基本功</h4><blockquote>
<p>浏览网⻚的本质是基于 HTTP 协议的一次或多次网络请求，这些请求用戶是可以直接查看的，比如按下 F12 再看看“网络”。</p>
<p>——某一线主播</p>
</blockquote>
<p>网络抓包通常有如下用途：</p>
<ol>
<li>查看真正的数据来源（常为XHR）</li>
<li>查看下载视频等数据</li>
<li>模拟请求完成登录</li>
<li><del>测试网站安全性</del></li>
</ol>
<p>其实对于写爬虫来说，主要用途只有一个，就是找到我们需要的数据的真正来源（当然如果使用selenium等方法加载网页内容可以不用分析数据来源，但是这样显然消耗更多资源且慢），稍后我们将会看到这一点。</p>
<h4 id="1-3-何为爬-amp-为何爬"><a href="#1-3-何为爬-amp-为何爬" class="headerlink" title="1.3. 何为爬 &amp; 为何爬"></a>1.3. 何为爬 &amp; 为何爬</h4><p>这个想必大家都是懂的，写爬虫归根结底还是为了替代人工进行重复 or 大量的操作，如果非常不熟悉爬虫这种程序可以去看rls的课。</p>
<h4 id="1-4-孰可爬"><a href="#1-4-孰可爬" class="headerlink" title="1.4. 孰可爬"></a>1.4. 孰可爬</h4><p>这部分是我们最重要的背景知识，爬网站之前请务必关注<strong>robots.txt</strong>（即域名+<code>/robots.txt</code>，要注意子域名的要求未必和主域名一样，切不可看到主域名可以爬就随便搞），这是网站与爬虫之间的“君子协议”，此处规定了什么可爬什么不可爬，下面是几个例子。</p>
<h5 id="1-4-1-百度"><a href="#1-4-1-百度" class="headerlink" title="1.4.1. 百度"></a>1.4.1. 百度</h5><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">User-agent: Baiduspider</span><br><span class="line">Disallow: /baidu</span><br><span class="line">Disallow: /s?</span><br><span class="line">Disallow: /ulink?</span><br><span class="line">Disallow: /link?</span><br><span class="line">Disallow: /home/news/data/</span><br><span class="line">Disallow: /bh</span><br><span class="line"></span><br><span class="line">User-agent: Googlebot</span><br><span class="line">Disallow: /baidu</span><br><span class="line">Disallow: /s?</span><br><span class="line">Disallow: /shifen/</span><br><span class="line">Disallow: /homepage/</span><br><span class="line">Disallow: /cpro</span><br><span class="line">Disallow: /ulink?</span><br><span class="line">Disallow: /link?</span><br><span class="line">Disallow: /home/news/data/</span><br><span class="line">Disallow: /bh</span><br><span class="line"></span><br><span class="line"># 中间略去若干内容</span><br><span class="line"></span><br><span class="line">User-agent: *</span><br><span class="line">Disallow: /</span><br></pre></td></tr></table></figure>

<p>解读：“除了我钦点的爬虫之外，其他拒不接待”</p>
<h5 id="1-4-2-淘宝-x2F-天猫"><a href="#1-4-2-淘宝-x2F-天猫" class="headerlink" title="1.4.2. 淘宝 &#x2F; 天猫"></a>1.4.2. 淘宝 &#x2F; 天猫</h5><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">User-agent: *</span><br><span class="line">Disallow: /</span><br></pre></td></tr></table></figure>

<p>解读：“莫挨老子”</p>
<h5 id="1-4-3-虎扑"><a href="#1-4-3-虎扑" class="headerlink" title="1.4.3. 虎扑"></a>1.4.3. 虎扑</h5><p>注意这里就出现了我们之前提到过的问题，<a target="_blank" rel="noopener" href="https://www.hupu.com/robots.txt">https://www.hupu.com/robots.txt</a> 如下：</p>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">User-agent: *</span><br><span class="line">Allow: /</span><br><span class="line"></span><br><span class="line">Sitemap: https://bbs.hupu.com/sitemap_index.xml</span><br><span class="line">Sitemap: https://bbs.hupu.com/sitemap/sitemap_boards.xml</span><br><span class="line">Sitemap: https://voice.hupu.com/sitemap_index.xml</span><br><span class="line">Sitemap: https://nba.hupu.com/players/index.xml</span><br></pre></td></tr></table></figure>

<p>解读：任何人都可以任意爬，还提供了站点地图供参考</p>
<p>但是<a target="_blank" rel="noopener" href="https://bbs.hupu.com/robots.txt">https://bbs.hupu.com/robots.txt</a> 则是这样的：</p>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">User-agent: *</span><br><span class="line">Request-rate: 50/1</span><br><span class="line">Disallow: /api/</span><br><span class="line">Disallow: /ajax/</span><br><span class="line">Disallow: /profile.php?*</span><br><span class="line">Disallow: /hack/</span><br><span class="line">Disallow: /template/</span><br><span class="line">Disallow: /attachment/</span><br><span class="line">Disallow: /gearfeedback/</span><br><span class="line">Disallow: /*_*.html$</span><br><span class="line"></span><br><span class="line">Sitemap: https://bbs.hupu.com/sitemap_index.xml</span><br><span class="line">Sitemap: https://bbs.hupu.com/sitemap/sitemap_boards.xml</span><br></pre></td></tr></table></figure>

<p>解读：法无禁止皆可为，但是速度不超过50次每秒（注意不同的爬虫其实对于一次爬取的理解是不同的，但是这是君子协议，所以对于我们自己写的爬虫也没有必要那么纠结，如果要仔细考虑的话，可以研究一下不同搜索引擎的爬虫对于这一问题的理解，可以参考<a target="_blank" rel="noopener" href="https://www.zhihu.com/robots.txt">知乎的robots.txt</a>以及<a target="_blank" rel="noopener" href="https://www.zhihu.com/question/264161961">相关提问</a>）</p>
<p>虽然虎扑社区比主站多了一些限制，但是我们看到这仍然是限制最少的（虽然限制<code>*_*.html$</code>但是新闻页并不是这样，而且50次每秒其实也不少），加上<del>众所周知的原因</del>虎扑前两天很出圈（至少在我写文档的时候是这样），所以我们将主要爬取虎扑的体育新闻作为演示。</p>
<h4 id="1-5-如何爬"><a href="#1-5-如何爬" class="headerlink" title="1.5. 如何爬"></a>1.5. 如何爬</h4><p>理想中的高性能爬虫架构：</p>
<p><img src="/./ideal.png"></p>
<p>直播用的入门版爬虫架构：</p>
<p><img src="/./simple.png"></p>
<h3 id="2-爬虫实战"><a href="#2-爬虫实战" class="headerlink" title="2. 爬虫实战"></a>2. 爬虫实战</h3><h4 id="2-1-准备"><a href="#2-1-准备" class="headerlink" title="2.1. 准备"></a>2.1. 准备</h4><ol>
<li>Python3:编程语言，推荐使用3.9.2或3.8.8及以上版本</li>
<li>Pycharm：强大的Python IDE，或者使用其他替代品也可，但不建议用Windows自带的idle</li>
<li>requests：一个用于发起请求的Python库</li>
<li>BeautifulSoup4：一个用于解析html的Python库</li>
<li>fake_useragent：一个用于生成User-Agent的Python库</li>
</ol>
<h4 id="2-2-自学内容"><a href="#2-2-自学内容" class="headerlink" title="2.2. 自学内容"></a>2.2. 自学内容</h4><p>上面只说到了比较重要的一些部分，下面还有些可能会用到的自学内容：</p>
<ul>
<li>js2py：在Python中执行JavaScript脚本</li>
<li>pyppeteer：通过headless的方法直接渲染网页</li>
<li>selenium：控制浏览器进行自动化测试的工具</li>
<li>requests.Session：保存会话，适用于需要Cookie的场景</li>
<li>requests添加代理ip</li>
<li>scrapy：真正的高性能爬虫框架</li>
</ul>
<h4 id="2-3-爬取演示"><a href="#2-3-爬取演示" class="headerlink" title="2.3. 爬取演示"></a>2.3. 爬取演示</h4><p>以爬取<a target="_blank" rel="noopener" href="https://bbs.hupu.com/502-1">虎扑某板块新闻列表</a>为例：</p>
<h5 id="2-3-1-引入必要的库"><a href="#2-3-1-引入必要的库" class="headerlink" title="2.3.1. 引入必要的库"></a>2.3.1. 引入必要的库</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> requests <span class="keyword">import</span> get, post</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">from</span> fake_useragent <span class="keyword">import</span> UserAgent</span><br><span class="line"><span class="keyword">from</span> urllib.request <span class="keyword">import</span> urljoin</span><br><span class="line"><span class="keyword">from</span> json <span class="keyword">import</span> dump</span><br><span class="line"><span class="keyword">from</span> time <span class="keyword">import</span> sleep  <span class="comment"># 如果网站要求以很低的频率爬，那么大概率会需要sleep</span></span><br></pre></td></tr></table></figure>

<h5 id="2-3-2-Cookie"><a href="#2-3-2-Cookie" class="headerlink" title="2.3.2. Cookie?"></a>2.3.2. Cookie?</h5><p>如果你点开了前面那个链接（而且你最近没有看过虎扑的话），你大概率会发现报了个错，不要怀疑，我没有写错URL，造成这样问题的原因大概是虎扑在切换新旧版面，直接点进去会莫名被转入旧版的页面，而旧版页面的URL大概不是这样写的。</p>
<p>那么这就要提到之前的一个问题，也就是“你是谁”的问题，虎扑会根据Cookie来判断你是否已经进入了新版页面，而这个Cookie显然是在首页被设置的，因此直接访问这一板块是行不通的。</p>
<p>从浏览器中获取cookie信息如下（因为内容太长所以我们直接保存在Python变量中）：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Cookie = <span class="string">&#x27;smidV2=20210720104859f6c99288e1bccb891e9ca9ce9d7bb6fe0055f24f4e677eec0; csrfToken=iGeSrk669wqQBcY5fKk2Diue; sensorsdata2015jssdkcross=%7B%22distinct_id%22%3A%2217ac1d102691c24-05465c49cc1a3d8-3e62684b-1296000-17ac1d1026a2685%22%2C%22%24device_id%22%3A%2217ac1d102691c24-05465c49cc1a3d8-3e62684b-1296000-17ac1d1026a2685%22%2C%22props%22%3A%7B%22%24latest_referrer%22%3A%22%22%2C%22%24latest_traffic_source_type%22%3A%22%E7%9B%B4%E6%8E%A5%E6%B5%81%E9%87%8F%22%2C%22%24latest_search_keyword%22%3A%22%E6%9C%AA%E5%8F%96%E5%88%B0%E5%80%BC_%E7%9B%B4%E6%8E%A5%E6%89%93%E5%BC%80%22%7D%7D; acw_tc=2f624a6816268527794733860e071fa5c73b1f702b456ad494e04ecfb5dc53; bbs_2020=1&#x27;</span></span><br></pre></td></tr></table></figure>

<h5 id="2-3-3-获取并解析新闻列表页"><a href="#2-3-3-获取并解析新闻列表页" class="headerlink" title="2.3.3. 获取并解析新闻列表页"></a>2.3.3. 获取并解析新闻列表页</h5><p>我们注意到，虎扑的新闻列表页URL大致可以表示为：</p>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https://bbs.hupu.com/502-&#123;PAGE&#125;</span><br></pre></td></tr></table></figure>

<p>注意到其中每一项的格式大致如下：</p>
<figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">&quot;/44314069.html&quot;</span> <span class="attr">target</span>=<span class="string">&quot;_blank&quot;</span> <span class="attr">class</span>=<span class="string">&quot;p-title&quot;</span>&gt;</span>[流言板]字母哥：要相信！我曾经上顿不接下顿，如今我是冠军<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>那么假如我们获取前10页的新闻详情链接：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">url = <span class="string">&#x27;https://bbs.hupu.com/&#x27;</span></span><br><span class="line">news_list = []</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">11</span>):</span><br><span class="line">    response = get(<span class="string">f&#x27;https://bbs.hupu.com/502-<span class="subst">&#123;i&#125;</span>&#x27;</span>, headers=&#123;<span class="string">&#x27;Cookie&#x27;</span>: Cookie&#125;)</span><br><span class="line">    soup = BeautifulSoup(response.content.decode(<span class="string">&#x27;utf-8&#x27;</span>), <span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line">    news = soup.find_all(<span class="string">&#x27;a&#x27;</span>, class_=<span class="string">&#x27;p-title&#x27;</span>)</span><br><span class="line">    <span class="keyword">for</span> n <span class="keyword">in</span> news:</span><br><span class="line">        news_list.append(urljoin(url, n.get(<span class="string">&#x27;href&#x27;</span>)))</span><br><span class="line">    sleep(<span class="number">0.02</span>)   <span class="comment"># 按照要求休息1/50秒</span></span><br></pre></td></tr></table></figure>

<h5 id="2-3-4-获取并解析新闻详情"><a href="#2-3-4-获取并解析新闻详情" class="headerlink" title="2.3.4. 获取并解析新闻详情"></a>2.3.4. 获取并解析新闻详情</h5><p>更好的做法是这里写一个类，但是一个自定义类写入文件又涉及到许多问题，所以我们简单的用字典表示，类似的，我们获取并解析网页：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">news_content = []</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> news_url <span class="keyword">in</span> news_list:</span><br><span class="line">    response = get(news_url, headers=&#123;<span class="string">&#x27;Cookie&#x27;</span>: Cookie&#125;)</span><br><span class="line">    soup = BeautifulSoup(response.content.decode(<span class="string">&#x27;utf-8&#x27;</span>), <span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line">    title = soup.find(<span class="string">&#x27;h1&#x27;</span>, class_=<span class="string">&#x27;name&#x27;</span>).text.strip()</span><br><span class="line">    content = soup.find(<span class="string">&#x27;div&#x27;</span>, class_=<span class="string">&#x27;thread-content-detail&#x27;</span>).text.strip().replace(<span class="string">&#x27;\r&#x27;</span>, <span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line">    news_content.append(&#123;</span><br><span class="line">        <span class="string">&#x27;url&#x27;</span>: news_url,</span><br><span class="line">        <span class="string">&#x27;title&#x27;</span>: title,</span><br><span class="line">        <span class="string">&#x27;content&#x27;</span>: content</span><br><span class="line">    &#125;)</span><br><span class="line">    sleep(<span class="number">0.02</span>)</span><br></pre></td></tr></table></figure>

<p>接下来我们将获取的内容保存为json</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dump(news_content, <span class="built_in">open</span>(<span class="string">&#x27;./hupu.json&#x27;</span>, <span class="string">&#x27;w&#x27;</span>), ensure_ascii=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>

<h4 id="2-4-关于反爬"><a href="#2-4-关于反爬" class="headerlink" title="2.4. 关于反爬"></a>2.4. 关于反爬</h4><p>接下来我们演示一个糟糕的反爬示例，<a target="_blank" rel="noopener" href="http://wjw.beijing.gov.cn/">北京卫健委</a>网站</p>
<p>如果我们直接执行</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">response = get(<span class="string">&#x27;http://wjw.beijing.gov.cn/&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p>我们会发现<code>response.text</code>很不对劲，而且其中比较明显能看到的是（当然我经过了格式化）</p>
<figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">id</span>=<span class="string">&#x27;notice-jiasule&#x27;</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">p</span>&gt;</span>当前网址：&lt;%- url %&gt;<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">p</span>&gt;</span>客户端特征：&lt;%- user_agent %&gt;<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">p</span>&gt;</span>拦截时间：&lt;%- now %&gt;<span class="symbol">&amp;nbsp;</span><span class="symbol">&amp;nbsp;</span>本次事件ID<span class="symbol">&amp;nbsp;</span>&lt;%- rule_id %&gt;<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>还有下面的</p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> content = _.<span class="title function_">template</span>(<span class="variable language_">document</span>.<span class="title function_">getElementById</span>(<span class="string">&#x27;content_tpl&#x27;</span>).<span class="property">innerHTML</span>)(&#123;</span><br><span class="line">    <span class="attr">error_403</span>: <span class="string">&#x27;&#x27;</span> || <span class="string">&#x27;当前访问疑似黑客攻击，已被网站管理员设置为拦截&#x27;</span>,</span><br><span class="line">    <span class="attr">url</span>: <span class="variable language_">document</span>.<span class="property">URL</span>.<span class="title function_">replace</span>(<span class="regexp">/\&lt;/g</span>,<span class="string">&quot;%3C&quot;</span>).<span class="title function_">replace</span>(<span class="regexp">/\&gt;/g</span>,<span class="string">&quot;%3E&quot;</span>),</span><br><span class="line">    <span class="attr">user_agent</span>: navigator.<span class="property">userAgent</span>,</span><br><span class="line">    <span class="attr">now</span>: <span class="keyword">new</span> <span class="title class_">Date</span>(<span class="keyword">new</span> <span class="title class_">Date</span>() - -<span class="number">8</span> * <span class="number">3600000</span>).<span class="title function_">toISOString</span>().<span class="title function_">substr</span>(<span class="number">0</span>, <span class="number">19</span>).<span class="title function_">replace</span>(<span class="string">&#x27;T&#x27;</span>, <span class="string">&#x27; &#x27;</span>),</span><br><span class="line">    <span class="attr">rule_id</span>: <span class="built_in">parseInt</span>(<span class="string">&#x27;[80001]&#x27;</span>.<span class="title function_">replace</span>(<span class="regexp">/\[|\]/g</span>, <span class="string">&#x27;&#x27;</span>)) || <span class="string">&#x27;&#x27;</span>,</span><br><span class="line">    <span class="attr">from</span>: <span class="built_in">encodeURIComponent</span>(<span class="variable language_">document</span>.<span class="property">referrer</span>.<span class="title function_">substr</span>(<span class="number">0</span>, <span class="number">1024</span>)),</span><br><span class="line">    <span class="attr">client_ip</span>: <span class="string">&#x27;59.66.16.88&#x27;</span>,</span><br><span class="line">    <span class="attr">ref</span>: <span class="built_in">encodeURIComponent</span>(<span class="variable language_">document</span>.<span class="property">URL</span>.<span class="title function_">substr</span>(<span class="number">0</span>, <span class="number">1024</span>))</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>

<p>不难发现这个网站所托管的“创宇云防御”屏蔽了我们的访问，而引起这一问题的原因，我们可以查看：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>response.request.headers</span><br><span class="line">&#123;<span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;python-requests/2.25.1&#x27;</span>, <span class="string">&#x27;Accept-Encoding&#x27;</span>: <span class="string">&#x27;gzip, deflate&#x27;</span>, <span class="string">&#x27;Accept&#x27;</span>: <span class="string">&#x27;*/*&#x27;</span>, <span class="string">&#x27;Connection&#x27;</span>: <span class="string">&#x27;keep-alive&#x27;</span>&#125;</span><br></pre></td></tr></table></figure>

<p>其中显然有一条<code>&#39;User-Agent&#39;: &#39;python-requests/2.25.1&#39;</code>，不打自招的爬虫行为，被屏蔽也并不奇怪（题外话，这个网站并没有设置robots.txt，因此双方都很难说谁对谁错）。好在现在这个网站不像去年一样会封ip地址，所以我们可以先演示错误示例。</p>
<p>我们当然可以模仿前面的做法，从浏览器中抄一个User-Agent过来，但是如果我们快速爬很多东西，最好还是每次换一个新的User-Agent减少被当作同一个用户的概率，因此我们使用如下方法：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ua = UserAgent(path=<span class="string">&#x27;./fake_useragent.json&#x27;</span>)</span><br><span class="line">response = get(<span class="string">&#x27;http://wjw.beijing.gov.cn/&#x27;</span>, headers=&#123;<span class="string">&#x27;User-Agent&#x27;</span>: ua.random&#125;)</span><br><span class="line"><span class="comment"># 没错，ua.random虽然是成员变量，但是每次使用的时候会改变自己，而不是用户调用一个类似于ua.random()的函数才会改变</span></span><br></pre></td></tr></table></figure>

<p>除此之外可能还会需要使用代理ip，如何获取代理地址请自学，使用方法如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">proxies = &#123;</span><br><span class="line">    <span class="string">&quot;http&quot;</span>: <span class="string">&quot;http://10.10.1.10:3128&quot;</span>,</span><br><span class="line">    <span class="string">&quot;https&quot;</span>: <span class="string">&quot;http://10.10.1.10:1080&quot;</span>,</span><br><span class="line">&#125;</span><br><span class="line">requests.get(<span class="string">&quot;http://example.org&quot;</span>, proxies=proxies)</span><br></pre></td></tr></table></figure>

<p>使用这两种方法可以避免很多反爬的系统（当然如果检查Cookie大概会很糟糕，可能需要许多Session，像前面那样写死Cookie实际上是非常偷懒的一种做法，但是我不想仔细研究那个Cookie到底在哪里设置以及使用Session应该按什么顺序操作）</p>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/Python/" rel="tag"># Python</a>
              <a href="/tags/%E6%9A%91%E5%9F%B9/" rel="tag"># 暑培</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2021/07/20/Python-%E9%80%9F%E6%88%90/" rel="prev" title="Python 速成">
      <i class="fa fa-chevron-left"></i> Python 速成
    </a></div>
      <div class="post-nav-item"></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#0-%E5%89%8D%E8%A8%80"><span class="nav-number">1.</span> <span class="nav-text">0. 前言</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-%E7%BD%91%E7%BB%9C%E8%AF%B7%E6%B1%82-amp-%E7%88%AC%E8%99%AB%E5%88%9D%E6%AD%A5"><span class="nav-number">2.</span> <span class="nav-text">1. 网络请求 &amp; 爬虫初步</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1-1-%E7%BB%88%E6%9E%81%E5%93%B2%E5%AD%A6%E4%B8%89%E5%A4%A7%E9%97%AE%EF%BC%88%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%A7%86%E8%A7%92%E4%B8%8B%E7%9A%84%E7%BD%91%E7%BB%9C%E8%AF%B7%E6%B1%82%EF%BC%89"><span class="nav-number">2.1.</span> <span class="nav-text">1.1. 终极哲学三大问（服务器视角下的网络请求）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#1-2-%E7%BD%91%E7%BB%9C%E6%8A%93%E5%8C%85%E5%9F%BA%E6%9C%AC%E5%8A%9F"><span class="nav-number">2.2.</span> <span class="nav-text">1.2. 网络抓包基本功</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#1-3-%E4%BD%95%E4%B8%BA%E7%88%AC-amp-%E4%B8%BA%E4%BD%95%E7%88%AC"><span class="nav-number">2.3.</span> <span class="nav-text">1.3. 何为爬 &amp; 为何爬</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#1-4-%E5%AD%B0%E5%8F%AF%E7%88%AC"><span class="nav-number">2.4.</span> <span class="nav-text">1.4. 孰可爬</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#1-4-1-%E7%99%BE%E5%BA%A6"><span class="nav-number">2.4.1.</span> <span class="nav-text">1.4.1. 百度</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#1-4-2-%E6%B7%98%E5%AE%9D-x2F-%E5%A4%A9%E7%8C%AB"><span class="nav-number">2.4.2.</span> <span class="nav-text">1.4.2. 淘宝 &#x2F; 天猫</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#1-4-3-%E8%99%8E%E6%89%91"><span class="nav-number">2.4.3.</span> <span class="nav-text">1.4.3. 虎扑</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#1-5-%E5%A6%82%E4%BD%95%E7%88%AC"><span class="nav-number">2.5.</span> <span class="nav-text">1.5. 如何爬</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-%E7%88%AC%E8%99%AB%E5%AE%9E%E6%88%98"><span class="nav-number">3.</span> <span class="nav-text">2. 爬虫实战</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#2-1-%E5%87%86%E5%A4%87"><span class="nav-number">3.1.</span> <span class="nav-text">2.1. 准备</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-2-%E8%87%AA%E5%AD%A6%E5%86%85%E5%AE%B9"><span class="nav-number">3.2.</span> <span class="nav-text">2.2. 自学内容</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-3-%E7%88%AC%E5%8F%96%E6%BC%94%E7%A4%BA"><span class="nav-number">3.3.</span> <span class="nav-text">2.3. 爬取演示</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#2-3-1-%E5%BC%95%E5%85%A5%E5%BF%85%E8%A6%81%E7%9A%84%E5%BA%93"><span class="nav-number">3.3.1.</span> <span class="nav-text">2.3.1. 引入必要的库</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2-3-2-Cookie"><span class="nav-number">3.3.2.</span> <span class="nav-text">2.3.2. Cookie?</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2-3-3-%E8%8E%B7%E5%8F%96%E5%B9%B6%E8%A7%A3%E6%9E%90%E6%96%B0%E9%97%BB%E5%88%97%E8%A1%A8%E9%A1%B5"><span class="nav-number">3.3.3.</span> <span class="nav-text">2.3.3. 获取并解析新闻列表页</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2-3-4-%E8%8E%B7%E5%8F%96%E5%B9%B6%E8%A7%A3%E6%9E%90%E6%96%B0%E9%97%BB%E8%AF%A6%E6%83%85"><span class="nav-number">3.3.4.</span> <span class="nav-text">2.3.4. 获取并解析新闻详情</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-4-%E5%85%B3%E4%BA%8E%E5%8F%8D%E7%88%AC"><span class="nav-number">3.4.</span> <span class="nav-text">2.4. 关于反爬</span></a></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="ayf"
      src="/images/avatar.png">
  <p class="site-author-name" itemprop="name">ayf</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives">
          <span class="site-state-item-count">3</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">2</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">2</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/ayf19" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;ayf19" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:me@anyi.fan" title="E-Mail → mailto:me@anyi.fan" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">ayf</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-area"></i>
    </span>
    <span title="站点总字数">30k</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="站点阅读时长">27 分钟</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  

</body>
</html>
